{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.12/site-packages (3.17.3)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (45.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.1.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.2)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.32.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.14.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.19.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.3.8)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0->snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade snowflake-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 tast 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake line: 204575\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '3', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import snowflake.connector as sf\n",
    "\n",
    "BASE_DIR = Path(r\"/home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/Monthly PO Data\").resolve()   # file base on your local path\n",
    "OUT_CSV  = BASE_DIR / \"combined_purchases.csv\"\n",
    "\n",
    "# ---- 1) Combine csv file\n",
    "if not OUT_CSV.exists():\n",
    "    TARGET_COLS = [\"PurchaseOrderID\",\"PurchaseOrderLineID\",\"ReceivedOuters\",\n",
    "                   \"ExpectedUnitPricePerOuter\",\"OrderDate\",\"SupplierID\"]\n",
    "    ALIASES = {\n",
    "        \"PurchaseOrderID\":           [\"purchaseorderid\",\"purchase_order_id\",\"poid\",\"orderid\"],\n",
    "        \"PurchaseOrderLineID\":       [\"purchaseorderlineid\",\"purchase_order_line_id\",\"polineid\",\"orderlineid\"],\n",
    "        \"ReceivedOuters\":            [\"receivedouters\",\"received_outers\",\"receivedoutersqty\",\"receivedoutersquantity\",\"received_qty\"],\n",
    "        \"ExpectedUnitPricePerOuter\": [\"expectedunitpriceperouter\",\"expected_unit_price_per_outer\",\"unitpriceperouter\",\"expectedprice\",\"unitprice\"],\n",
    "        \"OrderDate\":                 [\"orderdate\",\"order_date\",\"date\",\"order_dt\"],\n",
    "        \"SupplierID\":                [\"supplierid\",\"supplier_id\",\"vendorid\",\"vendor_id\"],\n",
    "    }\n",
    "    def norm(s): return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
    "    def pick_and_rename(df):\n",
    "        m = {c: norm(c) for c in df.columns}\n",
    "        rev = {}\n",
    "        for k,v in m.items():\n",
    "            if v not in rev: rev[v]=k\n",
    "        sel = {}\n",
    "        miss=[]\n",
    "        for tgt, aliases in ALIASES.items():\n",
    "            found=None\n",
    "            for a in aliases:\n",
    "                if a in rev: found=rev[a]; break\n",
    "            if not found: miss.append(tgt)\n",
    "            else: sel[tgt]=found\n",
    "        if miss: raise ValueError(f\"ç¼ºå°‘å¿…é¡»åˆ—: {miss}; æ–‡ä»¶åˆ—={list(df.columns)}\")\n",
    "        out = df[[sel[c] for c in TARGET_COLS]].copy()\n",
    "        out.columns = TARGET_COLS\n",
    "       \n",
    "        for c in [\"ReceivedOuters\",\"ExpectedUnitPricePerOuter\"]:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "      \n",
    "        out[\"OrderDate\"] = pd.to_datetime(out[\"OrderDate\"], errors=\"coerce\", format=\"%m/%d/%Y\")\n",
    "        out = out.dropna(subset=[\"PurchaseOrderID\",\"PurchaseOrderLineID\",\"OrderDate\"])\n",
    "        out[\"ReceivedOuters\"] = out[\"ReceivedOuters\"].fillna(0)\n",
    "        out[\"ExpectedUnitPricePerOuter\"] = out[\"ExpectedUnitPricePerOuter\"].fillna(0)\n",
    "        return out\n",
    "\n",
    "    frames=[]\n",
    "    files = sorted(BASE_DIR.glob(\"*.csv\"))\n",
    "    if not files: raise FileNotFoundError(f\"{BASE_DIR} ä¸‹æ²¡æœ‰ .csv\")\n",
    "    for p in files:\n",
    "        df = pd.read_csv(p, dtype=str, keep_default_na=False, na_values=[\"\",\"NULL\"])\n",
    "        frames.append(pick_and_rename(df))\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    combined.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"å·²ç”Ÿæˆæœ¬åœ°æ•´åˆï¼š{OUT_CSV}  è¡Œæ•°={len(combined):,}\")\n",
    "\n",
    "# ---- 2) To Snowflake ----\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"ETHANAN2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"svogymj-bxb71103\") \n",
    ")\n",
    "cs = conn.cursor()\n",
    "\n",
    "## change these line under to choose where we save the data to\n",
    "WH, DB, SC = \"ETL_WH\",\"ETL_DB\",\"ETL_SCHEMA\"\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB}.{SC}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH}\"); cs.execute(f\"USE DATABASE {DB}\"); cs.execute(f\"USE SCHEMA {SC}\")\n",
    "\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT csv_ff\n",
    "  TYPE=CSV\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY='\\\"'\n",
    "  PARSE_HEADER=TRUE\n",
    "  NULL_IF=('','NULL')\n",
    "  TRIM_SPACE=TRUE\n",
    "\"\"\")\n",
    "\n",
    "# Combine file\n",
    "cs.execute(f\"PUT 'file:///{OUT_CSV.as_posix()}' @purchases_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "staged_name = OUT_CSV.name + \".gz\" \n",
    "copy_sql = f\"\"\"\n",
    "COPY INTO purchases_detail\n",
    "FROM @purchases_stage/{staged_name}\n",
    "FILE_FORMAT=(FORMAT_NAME='csv_ff')\n",
    "MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\"\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE purchases_detail (\n",
    "  PurchaseOrderID           STRING,\n",
    "  PurchaseOrderLineID       STRING,\n",
    "  ReceivedOuters            NUMBER(18,4),\n",
    "  ExpectedUnitPricePerOuter NUMBER(18,4),\n",
    "  OrderDate                 DATE,\n",
    "  SupplierID                STRING\n",
    ")\n",
    "\"\"\")\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO'\")\n",
    "cs.execute(copy_sql)\n",
    "\n",
    "cs.execute(\"SELECT COUNT(*) FROM purchases_detail\")\n",
    "print(\"Snowflake line:\", cs.fetchone()[0])\n",
    "cs.execute(\"SELECT * FROM purchases_detail ORDER BY OrderDate, PurchaseOrderID LIMIT 5\")\n",
    "for r in cs.fetchall(): print(r)\n",
    "\n",
    "cs.close(); conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2 tast 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase_order_totals rows: 2025\n"
     ]
    }
   ],
   "source": [
    "# â€”â€” ç‰¢é ç‰ˆï¼šé‡è¿ + ä¸Šä¸‹æ–‡ä¸€æ¬¡æ€§è®¾ç½® + ä¸´æ—¶æ¸¸æ ‡ â€”â€” \n",
    "import os\n",
    "import snowflake.connector as sf\n",
    "\n",
    "ROLE = os.getenv(\"SNOW_ROLE\", \"ACCOUNTADMIN\")\n",
    "WH   = os.getenv(\"SNOW_WH\",   \"ETL_WH\")\n",
    "DB   = os.getenv(\"SNOW_DB\",   \"ETL_DB\")\n",
    "SC   = os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "# 1) å¼ºåˆ¶å»ºç«‹ä¸€ä¸ªæ–°çš„è¿æ¥ï¼šæŠŠä¸Šä¸‹æ–‡ç›´æ¥æ”¾åœ¨ connect é‡Œï¼›å¼€å¯ keep_alive\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"ETHANAN2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"svogymj-bxb71103\"), \n",
    "    role=ROLE,\n",
    "    warehouse=WH,\n",
    "    database=DB,\n",
    "    schema=SC,\n",
    "    client_session_keep_alive=True,\n",
    ")\n",
    "\n",
    "# 2) åœ¨åŒä¸€ä¸ª with é‡Œå®Œæˆæ‰€æœ‰ SQLï¼›é€€å‡º with åæ¸¸æ ‡ä¼šè‡ªåŠ¨å…³é—­\n",
    "with conn.cursor() as cs:\n",
    "    # è¡Œé‡‘é¢è§†å›¾\n",
    "    cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE VIEW purchases_line AS\n",
    "    SELECT\n",
    "      PurchaseOrderID,\n",
    "      PurchaseOrderLineID,\n",
    "      OrderDate,\n",
    "      SupplierID,\n",
    "      (ReceivedOuters * ExpectedUnitPricePerOuter) AS line_amount\n",
    "    FROM purchases_detail\n",
    "    \"\"\")\n",
    "\n",
    "    # è®¢å•çº§é‡‘é¢è¡¨\n",
    "    cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE purchase_order_totals AS\n",
    "    SELECT\n",
    "      PurchaseOrderID,\n",
    "      MIN(OrderDate) AS OrderDate,\n",
    "      ANY_VALUE(SupplierID) AS SupplierID,\n",
    "      SUM(line_amount) AS POAmount\n",
    "    FROM purchases_line\n",
    "    GROUP BY PurchaseOrderID\n",
    "    \"\"\")\n",
    "\n",
    "    # æ ¡éªŒ\n",
    "    cs.execute(\"SELECT COUNT(*) FROM purchase_order_totals\")\n",
    "    print(\"purchase_order_totals rows:\", cs.fetchone()[0])\n",
    "\n",
    "# å¯é€‰ï¼šä¿æŒè¿æ¥ç»™åç»­æ­¥éª¤ç”¨ï¼›å¦‚æœä¸éœ€è¦å°± conn.close()\n",
    "# conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2 tast 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°†ä¸Šä¼ çš„ XML æ–‡ä»¶ï¼š /home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/Supplier Transactions XML.xml\n",
      "Stageä¸­æ–‡ä»¶ï¼ˆå‰å‡ é¡¹ï¼‰ï¼š ['invoices_stage/Supplier Transactions XML.xml.gz']\n",
      "invoices_raw rows: 2438\n",
      "invoices rows: 2438\n",
      "invoices æ ·ä¾‹ï¼š\n",
      "('5', '3', datetime.date(1970, 1, 1), Decimal('7.0000'), '1')\n",
      "('5', '3', datetime.date(1970, 1, 1), Decimal('7.0000'), '1')\n",
      "('5', '3', datetime.date(1970, 1, 1), Decimal('7.0000'), '1')\n",
      "('5', '3', datetime.date(1970, 1, 1), Decimal('7.0000'), '1')\n",
      "('5', '3', datetime.date(1970, 1, 1), Decimal('7.0000'), '1')\n"
     ]
    }
   ],
   "source": [
    "# ==== Task 3ï¼šå‘ç¥¨ XML å…¨æµç¨‹ï¼ˆPUT â†’ åŸå§‹è£…è½½ â†’ è§£ææˆè¡¨ï¼‰====\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import snowflake.connector as sf\n",
    "\n",
    "# 0) è¿æ¥ï¼ˆå¦‚æœä½ ä¸Šé¢å·²æœ‰ connï¼Œå°±ä¼šå¤ç”¨ï¼‰\n",
    "try:\n",
    "    conn\n",
    "except NameError:\n",
    "    conn = sf.connect(\n",
    "        user=os.getenv(\"SNOW_USER\",\"<your_user>\"),\n",
    "        password=os.getenv(\"SNOW_PASSWORD\",\"<your_password>\"),\n",
    "        account=os.getenv(\"SNOW_ACCOUNT\",\"svogymj-bxb71103\"),\n",
    "        role=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\"),\n",
    "        warehouse=os.getenv(\"SNOW_WH\",\"ETL_WH\"),\n",
    "        database=os.getenv(\"SNOW_DB\",\"ETL_DB\"),\n",
    "        schema=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\"),\n",
    "        client_session_keep_alive=True,\n",
    "    )\n",
    "\n",
    "# 1) å®šä½ XML æ–‡ä»¶ï¼ˆä¼˜å…ˆä½ çš„å·¥ä½œåŒºè·¯å¾„ï¼Œæ‰¾ä¸åˆ°åˆ™å›é€€ /mnt/dataï¼‰\n",
    "candidates = [\n",
    "    Path(\"/home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/Supplier Transactions XML.xml\"),\n",
    "    Path(\"/mnt/data/Supplier Transactions XML.xml\"),\n",
    "]\n",
    "xml_path = next((p for p in candidates if p.exists()), None)\n",
    "if not xml_path:\n",
    "    raise FileNotFoundError(\"æ‰¾ä¸åˆ° XML æ–‡ä»¶ã€‚è¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æŠŠæ–‡ä»¶ä¸Šä¼ åˆ° /mnt/data åé‡è¯•ã€‚\")\n",
    "print(\"å°†ä¸Šä¼ çš„ XML æ–‡ä»¶ï¼š\", xml_path.as_posix())\n",
    "\n",
    "with conn.cursor() as cs:\n",
    "    # 2) Stage & æ–‡ä»¶æ ¼å¼ï¼ˆå¹‚ç­‰ï¼‰\n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS invoices_stage\")\n",
    "    cs.execute(\"CREATE OR REPLACE FILE FORMAT xml_ff TYPE=XML STRIP_OUTER_ELEMENT=TRUE\")\n",
    "\n",
    "    # 3) PUTï¼ˆè¦†ç›–ä¸Šä¼ ï¼‰\n",
    "    cs.execute(f\"PUT 'file:///{xml_path.as_posix()}' @invoices_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "    # ç®€çŸ­ç¡®è®¤\n",
    "    cs.execute(\"LIST @invoices_stage\")\n",
    "    print(\"Stageä¸­æ–‡ä»¶ï¼ˆå‰å‡ é¡¹ï¼‰ï¼š\", [r[0] for r in cs.fetchall()[:3]])\n",
    "\n",
    "    # 4) åŸå§‹è£…è½½åˆ° VARIANT è¡¨ï¼ˆå¹‚ç­‰ï¼‰\n",
    "    cs.execute(\"CREATE OR REPLACE TABLE invoices_raw (v VARIANT)\")\n",
    "    cs.execute(\"\"\"\n",
    "    COPY INTO invoices_raw\n",
    "    FROM @invoices_stage\n",
    "    FILE_FORMAT=(FORMAT_NAME='xml_ff')\n",
    "    ON_ERROR='ABORT_STATEMENT'\n",
    "    \"\"\")\n",
    "    cs.execute(\"SELECT COUNT(*) FROM invoices_raw\")\n",
    "    print(\"invoices_raw rows:\", cs.fetchone()[0])\n",
    "\n",
    "    # 5) è§£æä¸ºç»“æ„åŒ– invoices è¡¨\n",
    "    # - å…¼å®¹ä¸¤ç§XMLå½¢æ€ï¼šå•ä¸ªå¯¹è±¡ æˆ– æ•°ç»„/é‡å¤å…ƒç´ \n",
    "    # - ä½¿ç”¨ COALESCE + å¤šç§æ—¥æœŸæ ¼å¼å…œåº•\n",
    "    cs.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE invoices AS\n",
    "    WITH flat AS (\n",
    "      SELECT\n",
    "        r.value                           AS obj\n",
    "      FROM invoices_raw,\n",
    "           LATERAL FLATTEN(\n",
    "             input => CASE WHEN TYPEOF(v)='ARRAY' THEN v ELSE ARRAY_CONSTRUCT(v) END\n",
    "           ) AS r\n",
    "    )\n",
    "    SELECT\n",
    "      obj:SupplierInvoiceNumber::string                 AS InvoiceNumber,\n",
    "      obj:PurchaseOrderID::string                       AS PurchaseOrderID,\n",
    "      COALESCE(\n",
    "        TRY_TO_DATE(obj:TransactionDate::string,'YYYY-MM-DD'),\n",
    "        TRY_TO_DATE(obj:TransactionDate::string,'MM/DD/YYYY'),\n",
    "        TRY_TO_DATE(obj:TransactionDate::string,'M/D/YYYY'),\n",
    "        TRY_TO_DATE(obj:TransactionDate::string)\n",
    "      )                                                 AS InvoiceDate,\n",
    "      obj:AmountExcludingTax::number(18,4)              AS AmountExcludingTax,\n",
    "      obj:SupplierID::string                            AS SupplierID\n",
    "    FROM flat\n",
    "    WHERE obj:PurchaseOrderID IS NOT NULL\n",
    "    \"\"\")\n",
    "    # 6) æ ¡éªŒ\n",
    "    cs.execute(\"SELECT COUNT(*) FROM invoices\")\n",
    "    print(\"invoices rows:\", cs.fetchone()[0])\n",
    "\n",
    "    cs.execute(\"\"\"\n",
    "      SELECT * FROM invoices\n",
    "      ORDER BY InvoiceDate, PurchaseOrderID\n",
    "      LIMIT 5\n",
    "    \"\"\")\n",
    "    sample = cs.fetchall()\n",
    "    print(\"invoices æ ·ä¾‹ï¼š\")\n",
    "    for r in sample:\n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2 tast 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase_orders_and_invoices (TABLE) rows: 2438\n",
      "('3', datetime.date(2019, 1, 1), '5', Decimal('76734.00000000'), '5', Decimal('7.0000'), datetime.date(1970, 1, 1), Decimal('-76727.00000000'))\n",
      "('3', datetime.date(2019, 1, 1), '5', Decimal('76734.00000000'), '5', Decimal('7.0000'), datetime.date(1970, 1, 1), Decimal('-76727.00000000'))\n",
      "('3', datetime.date(2019, 1, 1), '5', Decimal('76734.00000000'), '5', Decimal('7.0000'), datetime.date(1970, 1, 1), Decimal('-76727.00000000'))\n",
      "('3', datetime.date(2019, 1, 1), '5', Decimal('76734.00000000'), '5', Decimal('7.0000'), datetime.date(1970, 1, 1), Decimal('-76727.00000000'))\n",
      "('3', datetime.date(2019, 1, 1), '5', Decimal('76734.00000000'), '5', Decimal('7.0000'), datetime.date(1970, 1, 1), Decimal('-76727.00000000'))\n"
     ]
    }
   ],
   "source": [
    "# ==== Task 4ï¼šé‡‡è´­ Ã— å‘ç¥¨åˆå¹¶ï¼Œäº§å‡ºå·®é¢ ====\n",
    "import os\n",
    "import snowflake.connector as sf\n",
    "\n",
    "# å¤ç”¨ç°æœ‰è¿æ¥ï¼›å¦‚æœä¸å­˜åœ¨å°±è¿ä¸€æ¬¡\n",
    "try:\n",
    "    conn\n",
    "except NameError:\n",
    "    conn = sf.connect(\n",
    "        user=os.getenv(\"SNOW_USER\",\"<your_user>\"),\n",
    "        password=os.getenv(\"SNOW_PASSWORD\",\"<your_password>\"),\n",
    "        account=os.getenv(\"SNOW_ACCOUNT\",\"svogymj-bxb71103\"),\n",
    "        role=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\"),\n",
    "        warehouse=os.getenv(\"SNOW_WH\",\"ETL_WH\"),\n",
    "        database=os.getenv(\"SNOW_DB\",\"ETL_DB\"),\n",
    "        schema=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\"),\n",
    "        client_session_keep_alive=True,\n",
    "    )\n",
    "\n",
    "DB = os.getenv(\"SNOW_DB\",\"ETL_DB\")\n",
    "SC = os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "core_sql = f\"\"\"\n",
    "SELECT\n",
    "  p.PurchaseOrderID,\n",
    "  p.OrderDate,                 -- äº¤æ˜“æ—¥æœŸï¼ˆè‹¥æƒ³ç”¨å‘ç¥¨æ—¥æœŸï¼Œæ”¹æˆ i.InvoiceDateï¼‰\n",
    "  p.SupplierID,\n",
    "  p.POAmount,\n",
    "  i.InvoiceNumber,\n",
    "  i.AmountExcludingTax,\n",
    "  i.InvoiceDate,\n",
    "  (i.AmountExcludingTax - p.POAmount) AS invoiced_vs_quoted\n",
    "FROM {DB}.{SC}.purchase_order_totals p\n",
    "JOIN {DB}.{SC}.invoices i\n",
    "  ON i.PurchaseOrderID = p.PurchaseOrderID\n",
    "WHERE i.InvoiceDate IS NOT NULL       -- è‹¥æƒ³ä¿ç•™ 1970-01-01 æˆ–ç©ºæ—¥æœŸï¼Œè¯·åˆ é™¤è¯¥è¡Œ\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cs:\n",
    "    # å…ˆæ¸…ç†ï¼Œå¹‚ç­‰\n",
    "    cs.execute(f\"DROP MATERIALIZED VIEW IF EXISTS {DB}.{SC}.purchase_orders_and_invoices\")\n",
    "    cs.execute(f\"DROP TABLE IF EXISTS {DB}.{SC}.purchase_orders_and_invoices\")\n",
    "\n",
    "    # ä¼˜å…ˆå»ºç‰©åŒ–è§†å›¾ï¼›ä¸æ”¯æŒå°±é€€å›è¡¨\n",
    "    try:\n",
    "        cs.execute(f\"CREATE MATERIALIZED VIEW {DB}.{SC}.purchase_orders_and_invoices AS {core_sql}\")\n",
    "        obj = \"MVIEW\"\n",
    "    except Exception as e:\n",
    "        # æŸäº›æƒé™/ç‰ˆæœ¬é™åˆ¶ä¸‹ MVIEW ä¸å¯ç”¨\n",
    "        cs.execute(f\"CREATE OR REPLACE TABLE {DB}.{SC}.purchase_orders_and_invoices AS {core_sql}\")\n",
    "        obj = \"TABLE\"\n",
    "\n",
    "    # æ ¡éªŒ\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.purchase_orders_and_invoices\")\n",
    "    total = cs.fetchone()[0]\n",
    "    print(f\"purchase_orders_and_invoices ({obj}) rows:\", total)\n",
    "\n",
    "    cs.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {DB}.{SC}.purchase_orders_and_invoices\n",
    "        ORDER BY OrderDate, PurchaseOrderID\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    for r in cs.fetchall():\n",
    "        print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2 tast 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG = dict(\n",
    "    host=\"localhost\",\n",
    "    port=55432,           # ä¸€å®šè¦å†™ 55432\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pgpwd123\"   # å°±æ˜¯ä½  docker run é‡Œè®¾ç½®çš„ POSTGRES_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… connected: PostgreSQL 15.14 (Debian 15.14-1.pgdg13+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "import psycopg2, time\n",
    "\n",
    "PG = dict(\n",
    "    host=\"host.docker.internal\",  # ğŸ‘ˆ å…³é”®ï¼šæ”¹è¿™é‡Œ\n",
    "    port=55432,                   # ä½ æ˜ å°„çš„ç«¯å£\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pgpwd123\",\n",
    ")\n",
    "\n",
    "deadline = time.time() + 15\n",
    "err = None\n",
    "while time.time() < deadline:\n",
    "    try:\n",
    "        with psycopg2.connect(**PG) as conn, conn.cursor() as cur:\n",
    "            cur.execute(\"select version()\")\n",
    "            print(\"âœ… connected:\", cur.fetchone()[0])\n",
    "            err = None\n",
    "            break\n",
    "    except Exception as e:\n",
    "        err = e\n",
    "        time.sleep(1)\n",
    "\n",
    "if err:\n",
    "    raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supplierid', 'suppliername', 'suppliercategoryid', 'primarycontactpersonid', 'alternatecontactpersonid', 'deliverymethodid', 'postalcityid', 'supplierreference', 'bankaccountname', 'bankaccountbranch', 'bankaccountcode', 'bankaccountnumber', 'bankinternationalcode', 'paymentdays', 'internalcomments', 'phonenumber', 'faxnumber', 'websiteurl', 'deliveryaddressline1', 'deliveryaddressline2', 'deliverypostalcode', 'deliverylocation', 'postaladdressline1', 'postaladdressline2', 'postalpostalcode', 'lasteditedby', 'validfrom', 'validto']\n"
     ]
    }
   ],
   "source": [
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(f\"DESC TABLE {DB}.{SC}.supplier_case\")\n",
    "    print([row[0] for row in cs.fetchall()])  # ç¬¬ä¸€åˆ—æ˜¯åˆ—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°†æ‰§è¡Œè„šæœ¬ï¼š /home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/supplier_case.pgsql\n",
      "âœ… Postgres å°±ç»ª\n",
      "âœ… å·²åœ¨ Postgres æ‰§è¡Œ supplier_case.pgsql\n",
      "âœ… å·²å¯¼å‡º CSVï¼š /home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/supplier_case.csv\n",
      "CSV è¡Œæ•°ï¼š 13\n",
      "CSV åˆ—ï¼š ['supplierid', 'suppliername', 'suppliercategoryid', 'primarycontactpersonid', 'alternatecontactpersonid', 'deliverymethodid', 'postalcityid', 'supplierreference', 'bankaccountname', 'bankaccountbranch', 'bankaccountcode', 'bankaccountnumber', 'bankinternationalcode', 'paymentdays', 'internalcomments', 'phonenumber', 'faxnumber', 'websiteurl', 'deliveryaddressline1', 'deliveryaddressline2', 'deliverypostalcode', 'deliverylocation', 'postaladdressline1', 'postaladdressline2', 'postalpostalcode', 'lasteditedby', 'validfrom', 'validto']\n",
      "âœ… Snowflake version: 9.27.0\n",
      "è¯†åˆ«åˆ—æ˜ å°„ï¼šSupplierID -> supplierid ï¼ŒPostalPostalCode -> postalcityid\n",
      "âœ… Snowflake.supplier_case è¡Œæ•°ï¼š 13\n",
      "âœ… supplier_basic è¡Œæ•°ï¼š 13\n",
      "æ ·ä¾‹ï¼š\n",
      "(1, 22202)\n",
      "(2, 80125)\n",
      "(3, 60523)\n",
      "(4, 95642)\n",
      "(5, 80125)\n"
     ]
    }
   ],
   "source": [
    "# ==== Task 5 æœ€ç»ˆç‰ˆï¼šPG â†’ CSV â†’ Snowflake â†’ supplier_basic ====\n",
    "import os, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import snowflake.connector as sf\n",
    "\n",
    "# -----------------------------\n",
    "# 1) è¿æ¥ Docker é‡Œçš„ Postgres\n",
    "# -----------------------------\n",
    "PG = dict(\n",
    "    host=\"host.docker.internal\",\n",
    "    port=55432,\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pgpwd123\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) æ‰¾åˆ° .pgsql è„šæœ¬\n",
    "# -----------------------------\n",
    "pgsql_candidates = [\n",
    "    Path(\"/home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5/supplier_case.pgsql\"),\n",
    "    Path(\"/mnt/data/supplier_case.pgsql\"),\n",
    "]\n",
    "pgsql_file = next((p for p in pgsql_candidates if p.exists()), None)\n",
    "if not pgsql_file:\n",
    "    raise FileNotFoundError(\"æ‰¾ä¸åˆ° supplier_case.pgsqlï¼Œè¯·ç¡®è®¤è·¯å¾„ã€‚\")\n",
    "print(\"å°†æ‰§è¡Œè„šæœ¬ï¼š\", pgsql_file.as_posix())\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ç­‰å¾… PG å°±ç»ªï¼ˆæœ€å¤š 30 ç§’ï¼‰\n",
    "# -----------------------------\n",
    "deadline = time.time() + 30\n",
    "while time.time() < deadline:\n",
    "    try:\n",
    "        with psycopg2.connect(**PG) as _:\n",
    "            break\n",
    "    except Exception:\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(\"ç­‰å¾… Postgres è¶…æ—¶ï¼Œè¯·ç¡®è®¤å®¹å™¨å·²å¯åŠ¨å¹¶ç›‘å¬ 55432 ç«¯å£ã€‚\")\n",
    "print(\"âœ… Postgres å°±ç»ª\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4) åœ¨ PG æ‰§è¡Œ .pgsqlï¼ˆåˆ›å»ºå¹¶å¡«å…… supplier_caseï¼‰\n",
    "# ---------------------------------------------------\n",
    "with psycopg2.connect(**PG) as pgconn, pgconn.cursor() as cur, open(pgsql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    cur.execute(f.read())\n",
    "    pgconn.commit()\n",
    "print(\"âœ… å·²åœ¨ Postgres æ‰§è¡Œ supplier_case.pgsql\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5) ä» PG å¯¼å‡º CSV åˆ°é¡¹ç›®ç›®å½•ï¼ˆè‡ªåŠ¨ mkdirï¼‰\n",
    "# ---------------------------------------------------\n",
    "proj_dir = Path(\"/home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5\")\n",
    "proj_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_out = proj_dir / \"supplier_case.csv\"\n",
    "\n",
    "with psycopg2.connect(**PG) as pgconn, pgconn.cursor() as cur, open(csv_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    cur.copy_expert(\"COPY (SELECT * FROM supplier_case) TO STDOUT WITH CSV HEADER\", f)\n",
    "print(\"âœ… å·²å¯¼å‡º CSVï¼š\", csv_out.as_posix())\n",
    "\n",
    "# è¯» CSVï¼ˆç”¨äºå»ºè¡¨ä¸è§†å›¾ï¼‰\n",
    "df = pd.read_csv(csv_out)\n",
    "print(\"CSV è¡Œæ•°ï¼š\", len(df))\n",
    "print(\"CSV åˆ—ï¼š\", list(df.columns))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6) è¿æ¥ Snowflakeï¼ˆæ–°å»ºç‹¬ç«‹è¿æ¥ï¼Œé¿å…ä¸ PG æ··æ·†ï¼‰\n",
    "# ---------------------------------------------------\n",
    "sf_conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\",\"Ethanan2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\",\"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\",\"svogymj-bxb71103\"),\n",
    "    role=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\"),\n",
    "    warehouse=os.getenv(\"SNOW_WH\",\"ETL_WH\"),\n",
    "    database=os.getenv(\"SNOW_DB\",\"ETL_DB\"),\n",
    "    schema=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\"),\n",
    "    client_session_keep_alive=True,\n",
    ")\n",
    "DB = os.getenv(\"SNOW_DB\",\"ETL_DB\")\n",
    "SC = os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(\"SELECT CURRENT_VERSION()\")\n",
    "    print(\"âœ… Snowflake version:\", cs.fetchone()[0])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7) æ¨æ–­åˆ—ç±»å‹ + è¯†åˆ« SupplierID/é‚®ç¼–åˆ—ï¼ˆä½¿ç”¨ä½ çš„çœŸå®åˆ—åï¼‰\n",
    "# ---------------------------------------------------\n",
    "tmap = {\n",
    "    \"int64\": \"NUMBER\",\n",
    "    \"float64\": \"FLOAT\",\n",
    "    \"object\": \"STRING\",\n",
    "    \"bool\": \"BOOLEAN\",\n",
    "    \"datetime64[ms]\": \"TIMESTAMP_NTZ\",\n",
    "    \"datetime64[ns]\": \"TIMESTAMP_NTZ\",\n",
    "}\n",
    "cols_def = \",\\n  \".join([f'\"{c}\" {tmap.get(str(t), \"STRING\")}' for c,t in df.dtypes.items()])\n",
    "\n",
    "# ä½ çš„ CSV ç¡®è®¤æœ‰è¿™ä¸¤åˆ—ï¼š\n",
    "sup_id_col = next((c for c in df.columns if c.lower()==\"supplierid\"), None)\n",
    "zip_col     = next((c for c in df.columns if c.lower() in {\n",
    "    \"postalpostalcode\",\"postal_code\",\"postalcode\",\"zip\",\"zipcode\",\"zip_code\",\n",
    "    \"supplierpostalcode\",\"postalcityid\"\n",
    "}), None)\n",
    "\n",
    "if not sup_id_col:\n",
    "    raise RuntimeError(f\"CSV ä¸­ç¼ºå°‘ SupplierID åˆ—ã€‚å½“å‰åˆ—={list(df.columns)}\")\n",
    "if not zip_col:\n",
    "    raise RuntimeError(f\"CSV ä¸­æ— æ³•è¯†åˆ«é‚®ç¼–åˆ—ã€‚å½“å‰åˆ—={list(df.columns)}\")\n",
    "\n",
    "print(f\"è¯†åˆ«åˆ—æ˜ å°„ï¼šSupplierID -> {sup_id_col} ï¼ŒPostalPostalCode -> {zip_col}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8) STAGE / FILE FORMAT / PUT / COPY / VIEW\n",
    "# ---------------------------------------------------\n",
    "full_tbl = f\"{DB}.{SC}.supplier_case\"\n",
    "\n",
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS supplier_stage\")\n",
    "    cs.execute(\"\"\"\n",
    "      CREATE OR REPLACE FILE FORMAT csv_ff_sc\n",
    "      TYPE=CSV\n",
    "      FIELD_OPTIONALLY_ENCLOSED_BY='\\\"'\n",
    "      PARSE_HEADER=TRUE\n",
    "      NULL_IF=('','NULL')\n",
    "      TRIM_SPACE=TRUE\n",
    "    \"\"\")\n",
    "\n",
    "    cs.execute(f\"CREATE OR REPLACE TABLE {full_tbl} (\\n  {cols_def}\\n)\")\n",
    "\n",
    "    # PUTï¼šè·¯å¾„åŒ…å«ç©ºæ ¼ï¼Œä½¿ç”¨ file:/// + å¼•å·\n",
    "    cs.execute(f\"PUT 'file:///{csv_out.as_posix()}' @supplier_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "    # COPYï¼šPARSE_HEADER=TRUE é…å¥— MATCH_BY_COLUMN_NAME\n",
    "    cs.execute(f\"\"\"\n",
    "      COPY INTO {full_tbl}\n",
    "      FROM @supplier_stage\n",
    "      FILE_FORMAT = (FORMAT_NAME = 'csv_ff_sc')\n",
    "      MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n",
    "      ON_ERROR = 'ABORT_STATEMENT'\n",
    "    \"\"\")\n",
    "\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {full_tbl}\")\n",
    "    print(\"âœ… Snowflake.supplier_case è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "    # è§†å›¾é‡Œå¯¹å®é™…åˆ—ååŠ åŒå¼•å·ï¼Œé¿å…å¤§å°å†™é—®é¢˜\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.supplier_basic AS\n",
    "      SELECT\n",
    "        \"{sup_id_col}\" AS SupplierID,\n",
    "        \"{zip_col}\"    AS PostalPostalCode\n",
    "      FROM {DB}.{SC}.supplier_case\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.supplier_basic\")\n",
    "    print(\"âœ… supplier_basic è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "    cs.execute(f\"SELECT * FROM {DB}.{SC}.supplier_basic LIMIT 5\")\n",
    "    print(\"æ ·ä¾‹ï¼š\")\n",
    "    for r in cs.fetchall():\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2 tast 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Snowflake: 9.27.0\n",
      "âœ… å·² PUT Gazetteer åˆ° @weather_stage\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "100205 (P0000): DML operation to table PYB59698.ETL_DB.ETL_SCHEMA.ZIP_LOCATIONS failed on column GEOG with error: GeoJSON::Point: Invalid Lng/Lat pair: '799292,1.66848e+08'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 57\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sf_conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cs:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# åŸå§‹ä¸‰åˆ—ï¼šGEOID INTPTLAT INTPTLONG\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     cs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m      CREATE OR REPLACE TEMP TABLE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip_gaz_raw AS\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m      SELECT $1::string AS GEOID, $2::string AS INTPTLAT, $3::string AS INTPTLONG\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m      FROM @weather_stage/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgaz_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (FILE_FORMAT => \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv_ff\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;43m      CREATE OR REPLACE TABLE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSC\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.zip_locations AS\u001b[39;49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;43m      SELECT\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;43m        GEOID::string AS zip,\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;43m        TRY_TO_DOUBLE(INTPTLAT)  AS lat,\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;43m        TRY_TO_DOUBLE(INTPTLONG) AS lon,\u001b[39;49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;43m        TO_GEOGRAPHY(ST_MAKEPOINT(TRY_TO_DOUBLE(INTPTLONG), TRY_TO_DOUBLE(INTPTLAT))) AS geog\u001b[39;49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;43m      FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSC\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.zip_gaz_raw\u001b[39;49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;43m      WHERE LENGTH(GEOID)=5\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;43m        AND TRY_TO_DOUBLE(INTPTLAT)  IS NOT NULL\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;43m        AND TRY_TO_DOUBLE(INTPTLONG) IS NOT NULL\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     cs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT COUNT(*) FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip_locations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… zip_locations è¡Œæ•°ï¼š\u001b[39m\u001b[38;5;124m\"\u001b[39m, cs\u001b[38;5;241m.\u001b[39mfetchone()[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/cursor.py:1134\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _force_qmark_paramstyle, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1131\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1134\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:286\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    265\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    294\u001b[0m             error_class,\n\u001b[1;32m    295\u001b[0m             error_value,\n\u001b[1;32m    296\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:341\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 341\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:217\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    215\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    218\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    219\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    220\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    221\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    222\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    225\u001b[0m     ),\n\u001b[1;32m    226\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    227\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    228\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 100205 (P0000): DML operation to table PYB59698.ETL_DB.ETL_SCHEMA.ZIP_LOCATIONS failed on column GEOG with error: GeoJSON::Point: Invalid Lng/Lat pair: '799292,1.66848e+08'."
     ]
    }
   ],
   "source": [
    "# ==== Task 6ï¼ˆMarketplace ç‰ˆï¼‰ï¼šZIP â†’ æœ€è¿‘ç«™ç‚¹ â†’ æ—¥æœ€é«˜æ¸© TMAX ====\n",
    "import os\n",
    "from pathlib import Path\n",
    "import snowflake.connector as sf\n",
    "\n",
    "# ---------- 0) Snowflake è¿æ¥ ----------\n",
    "try:\n",
    "    sf_conn\n",
    "except NameError:\n",
    "    sf_conn = sf.connect(\n",
    "        user=os.getenv(\"SNOW_USER\",\"<your_user>\"),\n",
    "        password=os.getenv(\"SNOW_PASSWORD\",\"<your_password>\"),\n",
    "        account=os.getenv(\"SNOW_ACCOUNT\",\"svogymj-bxb71103\"),\n",
    "        role=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\"),\n",
    "        warehouse=os.getenv(\"SNOW_WH\",\"ETL_WH\"),\n",
    "        database=os.getenv(\"SNOW_DB\",\"ETL_DB\"),\n",
    "        schema=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\"),\n",
    "        client_session_keep_alive=True,\n",
    "    )\n",
    "\n",
    "DB = os.getenv(\"SNOW_DB\",\"ETL_DB\")\n",
    "SC = os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "IMPORTED_DB = \"WEATHER__ENVIRONMENT\"     # ä½ è®¢é˜…åˆ°çš„ Imported DB\n",
    "PROVIDER_SCH = \"CYBERSYN\"                 # Provider çš„ schema\n",
    "\n",
    "STATION_TBL = f\"{IMPORTED_DB}.{PROVIDER_SCH}.NOAA_WEATHER_STATION_INDEX\"\n",
    "TS_TBL      = f\"{IMPORTED_DB}.{PROVIDER_SCH}.NOAA_WEATHER_METRICS_TIMESERIES\"\n",
    "\n",
    "DATA_DIR = Path(\"/home/jovyan/MGTA SQL/final project/SQL_FINAL_PROJECT/Data-5\")\n",
    "gaz_file = DATA_DIR / \"2021_Gaz_zcta_national.txt\"\n",
    "if not gaz_file.exists():\n",
    "    raise FileNotFoundError(\"æœªæ‰¾åˆ° 2021_Gaz_zcta_national.txtï¼Œè¯·æ”¾åˆ° Data-5 ç›®å½•ã€‚\")\n",
    "\n",
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(\"SELECT CURRENT_VERSION()\")\n",
    "    print(\"âœ… Snowflake:\", cs.fetchone()[0])\n",
    "\n",
    "# ---------- 1) Stage + File Format + PUTï¼ˆGazetteer TSVï¼‰ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS weather_stage\")\n",
    "    cs.execute(\"\"\"\n",
    "      CREATE OR REPLACE FILE FORMAT tsv_ff\n",
    "      TYPE=CSV FIELD_DELIMITER='\\t' SKIP_HEADER=1 NULL_IF=('','NULL') TRIM_SPACE=TRUE\n",
    "    \"\"\")\n",
    "    cs.execute(f\"PUT 'file:///{gaz_file.as_posix()}' @weather_stage OVERWRITE=TRUE AUTO_COMPRESS=TRUE\")\n",
    "    print(\"âœ… å·² PUT Gazetteer åˆ° @weather_stage\")\n",
    "\n",
    "# ---------- 2) ZIP â†’ ç»çº¬åº¦ï¼ˆzip_locationsï¼‰ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    # åŸå§‹ä¸‰åˆ—ï¼šGEOID INTPTLAT INTPTLONG\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE TEMP TABLE {DB}.{SC}.zip_gaz_raw AS\n",
    "      SELECT $1::string AS GEOID, $2::string AS INTPTLAT, $3::string AS INTPTLONG\n",
    "      FROM @weather_stage/{gaz_file.name} (FILE_FORMAT => 'tsv_ff')\n",
    "    \"\"\")\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE TABLE {DB}.{SC}.zip_locations AS\n",
    "      SELECT\n",
    "        GEOID::string AS zip,\n",
    "        TRY_TO_DOUBLE(INTPTLAT)  AS lat,\n",
    "        TRY_TO_DOUBLE(INTPTLONG) AS lon,\n",
    "        TO_GEOGRAPHY(ST_MAKEPOINT(TRY_TO_DOUBLE(INTPTLONG), TRY_TO_DOUBLE(INTPTLAT))) AS geog\n",
    "      FROM {DB}.{SC}.zip_gaz_raw\n",
    "      WHERE LENGTH(GEOID)=5\n",
    "        AND TRY_TO_DOUBLE(INTPTLAT)  IS NOT NULL\n",
    "        AND TRY_TO_DOUBLE(INTPTLONG) IS NOT NULL\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.zip_locations\")\n",
    "    print(\"âœ… zip_locations è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "# ---------- 3) ç«™ç‚¹ç´¢å¼•ï¼ˆMarketplaceï¼‰ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    # ç«™ç‚¹ç´¢å¼•é€šå¸¸å«ï¼šSTATION_ID / LATITUDE / LONGITUDE\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.weather_stations AS\n",
    "      SELECT\n",
    "        station_id::string AS station_id,\n",
    "        latitude::float    AS latitude,\n",
    "        longitude::float   AS longitude,\n",
    "        TO_GEOGRAPHY(ST_MAKEPOINT(longitude::float, latitude::float)) AS geog\n",
    "      FROM {STATION_TBL}\n",
    "      WHERE latitude IS NOT NULL AND longitude IS NOT NULL\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.weather_stations\")\n",
    "    print(\"âœ… weather_stations è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "# ---------- 4) é€æ—¥ TMAXï¼ˆMarketplaceï¼‰ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    # Timeseries é€šå¸¸å«ï¼šSTATION_ID / DATE / METRIC / VALUE / UNIT\n",
    "    # è¿™é‡Œç­›é€‰ METRIC='TMAX'ï¼Œå¹¶å°†å¯èƒ½çš„ 0.1â„ƒ æ ‡åº¦æ ‡å‡†åŒ–ä¸º â„ƒï¼ˆ>200 åˆ™ /10ï¼‰\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.weather_tmax AS\n",
    "      SELECT\n",
    "        station_id::string                                     AS station_id,\n",
    "        TO_DATE(date)                                          AS weather_date,\n",
    "        CASE\n",
    "          WHEN value IS NULL THEN NULL\n",
    "          WHEN ABS(value::float) > 200 THEN (value::float)/10  -- NOAA å¸¸è§åˆ»åº¦ï¼š0.1â„ƒ â†’ â„ƒ\n",
    "          ELSE value::float\n",
    "        END                                                    AS tmax_value\n",
    "      FROM {TS_TBL}\n",
    "      WHERE UPPER(metric) = 'TMAX'\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.weather_tmax\")\n",
    "    print(\"âœ… weather_tmax è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "# ---------- 5) ZIP â†’ æœ€è¿‘ç«™ç‚¹ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    # supplier_basic çš„ ZIP æ˜ å°„åˆ°åæ ‡\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.supplier_zip_points AS\n",
    "      SELECT\n",
    "        s.PostalPostalCode AS zip,\n",
    "        z.lat, z.lon, z.geog\n",
    "      FROM {DB}.{SC}.supplier_basic s\n",
    "      JOIN {DB}.{SC}.zip_locations z\n",
    "        ON z.zip = s.PostalPostalCode\n",
    "    \"\"\")\n",
    "\n",
    "    # æœ€è¿‘ç«™ç‚¹ï¼ˆå»ºè®®åŠ  50km é™åˆ¶ï¼›å¦‚æ•°æ®ç¨€ç–å¯ç§»é™¤ WHEREï¼‰\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.zip_nearest_station AS\n",
    "      SELECT\n",
    "        p.zip,\n",
    "        w.station_id,\n",
    "        ST_DISTANCE(p.geog, w.geog) AS distance_m\n",
    "      FROM {DB}.{SC}.supplier_zip_points p\n",
    "      JOIN {DB}.{SC}.weather_stations w\n",
    "      WHERE ST_DISTANCE(p.geog, w.geog) < 50000\n",
    "      QUALIFY ROW_NUMBER() OVER (PARTITION BY p.zip ORDER BY ST_DISTANCE(p.geog, w.geog)) = 1\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.zip_nearest_station\")\n",
    "    print(\"âœ… zip_nearest_station è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "# ---------- 6) äº§å‡ºæœ€ç»ˆç»“æœ ----------\n",
    "with sf_conn.cursor() as cs:\n",
    "    cs.execute(f\"\"\"\n",
    "      CREATE OR REPLACE VIEW {DB}.{SC}.supplier_zip_code_weather AS\n",
    "      SELECT\n",
    "        s.PostalPostalCode              AS PostalPostalCode,\n",
    "        t.weather_date                  AS weather_date,\n",
    "        t.tmax_value                    AS tmax_value\n",
    "      FROM {DB}.{SC}.supplier_basic s\n",
    "      JOIN {DB}.{SC}.zip_nearest_station z\n",
    "        ON z.zip = s.PostalPostalCode\n",
    "      JOIN {DB}.{SC}.weather_tmax t\n",
    "        ON t.station_id = z.station_id\n",
    "      WHERE t.weather_date IS NOT NULL\n",
    "    \"\"\")\n",
    "    cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.supplier_zip_code_weather\")\n",
    "    print(\"âœ… supplier_zip_code_weather è¡Œæ•°ï¼š\", cs.fetchone()[0])\n",
    "\n",
    "    cs.execute(f\"\"\"\n",
    "      SELECT * FROM {DB}.{SC}.supplier_zip_code_weather\n",
    "      ORDER BY PostalPostalCode, weather_date\n",
    "      LIMIT 5\n",
    "    \"\"\")\n",
    "    print(\"æ ·ä¾‹ï¼š\")\n",
    "    for r in cs.fetchall():\n",
    "        print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
