{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.12/site-packages (3.17.3)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (45.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.1.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.2)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.32.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.14.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.19.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.3.8)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0->snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user= 'mnonog',\n",
    "    password = 'KayaNatinToL0RD!',\n",
    "    account='cejmwpt-djb91267'\n",
    "    )\n",
    "\n",
    "#https://cejmwpt-djb91267.snowflakecomputing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs.execute(\"YOUR SQL COMMAND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff6104bda0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS my_first_warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs.execute(\"USE WAREHOUSE different_warehouse_mg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff6104bda0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS testdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff6104bda0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE SCHEMA IF NOT EXISTS testschema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff6104bda0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\n",
    "\"CREATE OR REPLACE TABLE \"    \n",
    "\"test_table(col1 integer, col2 string)\")\n",
    "cs.execute(\n",
    "\"INSERT INTO test_table(col1, col2) \"\n",
    "    \t\t\"VALUES (123, 'test string1'), (456, 'test string2')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cs.execute(\"PUT file:///tmp/data/file* @test_table_stage\") and then cs.execute(\"COPY INTO test_table FROM @test_table_stage\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(123, 'test string1'), (456, 'test string2')]\n"
     ]
    }
   ],
   "source": [
    "cs.execute('SELECT * FROM test_table')\n",
    "print(cs.fetchmany(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUT file:///data/mydata.csv @%t1/United_States/California/Los_Angeles/2016/06/01/11/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-connector-python\n",
      "  Downloading snowflake_connector_python-3.17.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m792.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting boto3>=1.24 (from snowflake-connector-python)\n",
      "  Downloading boto3-1.40.26-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.34.148)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (42.0.8)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (24.2.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (24.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2025.7.14)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.15.4)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.2.2)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Collecting botocore>=1.24 (from snowflake-connector-python)\n",
      "  Downloading botocore-1.40.26-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.24->snowflake-connector-python)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.24->snowflake-connector-python) (1.26.19)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.16.0)\n",
      "Downloading snowflake_connector_python-3.17.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.40.26-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.40.26-py3-none-any.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: asn1crypto, botocore, s3transfer, boto3, snowflake-connector-python\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.148\n",
      "    Uninstalling botocore-1.34.148:\n",
      "      Successfully uninstalled botocore-1.34.148\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.10.2\n",
      "    Uninstalling s3transfer-0.10.2:\n",
      "      Successfully uninstalled s3transfer-0.10.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.30 requires botocore==1.34.148, but you have botocore 1.40.26 which is incompatible.\n",
      "awscli 1.33.30 requires s3transfer<0.11.0,>=0.10.0, but you have s3transfer 0.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 boto3-1.40.26 botocore-1.40.26 s3transfer-0.13.1 snowflake-connector-python-3.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (2.2.3)\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.1-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lxml-6.0.1-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary, lxml\n",
      "Successfully installed lxml-6.0.1 psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 如已安装可跳过对应行\n",
    "%pip install --upgrade snowflake-connector-python\n",
    "%pip install psycopg2-binary pandas lxml python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7b3ffec9ead0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import snowflake.connector as sf\n",
    "\n",
    "# === 建议用环境变量/ .env ===\n",
    "SNOW_USER=os.getenv(\"SNOW_USER\",\"<你的user>\")\n",
    "SNOW_PASSWORD=os.getenv(\"SNOW_PASSWORD\",\"<你的password>\")\n",
    "SNOW_ACCOUNT=os.getenv(\"SNOW_ACCOUNT\",\"svogymj-bxb71103\")   # 只写标识，不要写 https://...\n",
    "SNOW_ROLE=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\")\n",
    "WH_NAME=os.getenv(\"SNOW_WH\",\"ETL_WH\")\n",
    "DB_NAME=os.getenv(\"SNOW_DB\",\"ETL_DB\")\n",
    "SCHEMA_NAME=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "conn = sf.connect(user='ETHANAN2000', password='An67087833@123', account='svogymj-bxb71103')\n",
    "cs = conn.cursor()\n",
    "\n",
    "# 基础对象\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH_NAME} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB_NAME}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB_NAME}.{SCHEMA_NAME}\")\n",
    "cs.execute(f\"USE ROLE {SNOW_ROLE}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH_NAME}\")\n",
    "cs.execute(f\"USE DATABASE {DB_NAME}\")\n",
    "cs.execute(f\"USE SCHEMA {SCHEMA_NAME}\")\n",
    "\n",
    "# 统一 stage / 文件格式\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS invoices_stage\")\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS supplier_stage\")\n",
    "\n",
    "cs.execute(\"\"\"CREATE OR REPLACE FILE FORMAT csv_ff \n",
    "  TYPE=CSV FIELD_OPTIONALLY_ENCLOSED_BY='\\\"' SKIP_HEADER=1 NULL_IF=('','NULL')\"\"\")\n",
    "cs.execute(\"\"\"CREATE OR REPLACE FILE FORMAT xml_ff TYPE=XML STRIP_OUTER_ELEMENT=TRUE\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 0) 连接 ----------\n",
    "# 建议把用户名/密码放到环境变量 SNOW_USER / SNOW_PASSWORD / SNOW_ACCOUNT\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"ETHANAN2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"svogymj-bxb71103\")  # 只写标识，不要 https:// 前缀\n",
    ")\n",
    "cs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_4817/3917673208.py:78: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成本地整合文件：/home/jovyan/MGTA 464 SQL/group project/SQL_FINAL_PROJECT/Data-5/Monthly PO Data/combined_purchases.csv 行数=24,549\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "100080 (22000): Number of columns in file (23) does not match that of the corresponding table (6), use file format option error_on_column_count_mismatch=false to ignore this error\n  File '2020-12.csv.gz', line 3, character 1\n  Row 1 starts at line 2, column \"PURCHASES_DETAIL\"[23]\n  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# 9) COPY（按列名匹配；这里列数=6，与目标表完全一致，不会再报列数不匹配/日期当数字）\u001b[39;00m\n\u001b[1;32m    137\u001b[0m cs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALTER SESSION SET DATE_INPUT_FORMAT=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUTO\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m \u001b[43mcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;43mCOPY INTO purchases_detail\u001b[39;49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;43mFROM @purchases_stage\u001b[39;49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;43mFILE_FORMAT=(FORMAT_NAME=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv_ff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;43mMATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\u001b[39;49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;43mON_ERROR=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mABORT_STATEMENT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# 10) 校验\u001b[39;00m\n\u001b[1;32m    147\u001b[0m cs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT COUNT(*) FROM purchases_detail\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/cursor.py:1134\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _force_qmark_paramstyle, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1131\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1134\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:286\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    265\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    294\u001b[0m             error_class,\n\u001b[1;32m    295\u001b[0m             error_value,\n\u001b[1;32m    296\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:341\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 341\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/snowflake/connector/errors.py:217\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    215\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    218\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    219\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    220\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    221\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    222\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    225\u001b[0m     ),\n\u001b[1;32m    226\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    227\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    228\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 100080 (22000): Number of columns in file (23) does not match that of the corresponding table (6), use file format option error_on_column_count_mismatch=false to ignore this error\n  File '2020-12.csv.gz', line 3, character 1\n  Row 1 starts at line 2, column \"PURCHASES_DETAIL\"[23]\n  If you would like to continue loading when an error is encountered, use other values such as 'SKIP_FILE' or 'CONTINUE' for the ON_ERROR option. For more information on loading options, please run 'info loading_data' in a SQL client."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowflake.connector as sf\n",
    "\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "BASE_DIR = Path(r\"/home/jovyan/MGTA 464 SQL/group project/SQL_FINAL_PROJECT/Data-5/Monthly PO Data\").resolve()\n",
    "OUT_CSV  = BASE_DIR / \"combined_purchases.csv\"   # 统一输出文件\n",
    "\n",
    "# 2) 需要保留并标准化到 Snowflake 的列（目标列名）\n",
    "TARGET_COLS = [\n",
    "    \"PurchaseOrderID\",\n",
    "    \"PurchaseOrderLineID\",\n",
    "    \"ReceivedOuters\",\n",
    "    \"ExpectedUnitPricePerOuter\",\n",
    "    \"OrderDate\",\n",
    "    \"SupplierID\",\n",
    "]\n",
    "\n",
    "# 3) 列名别名表（尽量覆盖你文件里的各种写法；不够的话再加几种）\n",
    "ALIASES = {\n",
    "    \"PurchaseOrderID\":           [\"purchaseorderid\", \"purchase_order_id\", \"poid\", \"orderid\"],\n",
    "    \"PurchaseOrderLineID\":       [\"purchaseorderlineid\", \"purchase_order_line_id\", \"polineid\", \"orderlineid\"],\n",
    "    \"ReceivedOuters\":            [\"receivedouters\", \"received_outers\", \"receivedoutersqty\", \"receivedoutersquantity\", \"received_qty\"],\n",
    "    \"ExpectedUnitPricePerOuter\": [\"expectedunitpriceperouter\", \"expected_unit_price_per_outer\", \"unitpriceperouter\", \"expectedprice\", \"unitprice\"],\n",
    "    \"OrderDate\":                 [\"orderdate\", \"order_date\", \"date\", \"order_dt\"],\n",
    "    \"SupplierID\":                [\"supplierid\", \"supplier_id\", \"vendorid\", \"vendor_id\"],\n",
    "}\n",
    "\n",
    "def norm(name: str) -> str:\n",
    "    \"\"\"规范化列名：只保留字母数字并小写，便于匹配\"\"\"\n",
    "    return \"\".join(ch.lower() for ch in name if ch.isalnum())\n",
    "\n",
    "def pick_and_rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"从原始 df 里按别名表挑出需要的列，并重命名为标准列名\"\"\"\n",
    "    orig_to_norm = {c: norm(c) for c in df.columns}\n",
    "    norm_to_orig = {v: k for k, v in orig_to_norm.items()}  # 取第一个出现的映射即可\n",
    "\n",
    "    selected = {}\n",
    "    missing  = []\n",
    "    for tgt, alias_list in ALIASES.items():\n",
    "        found = None\n",
    "        for alias in alias_list:\n",
    "            if alias in norm_to_orig:\n",
    "                found = norm_to_orig[alias]\n",
    "                break\n",
    "        if found is None:\n",
    "            missing.append(tgt)\n",
    "        else:\n",
    "            selected[tgt] = found\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"缺少必须列：{missing}; 文件列={list(df.columns)}\")\n",
    "\n",
    "\n",
    "    out = df[[selected[c] for c in TARGET_COLS]].copy()\n",
    "    out.columns = TARGET_COLS\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "csv_files = sorted(BASE_DIR.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"在 {BASE_DIR} 下没有找到 .csv 文件\")\n",
    "\n",
    "for p in csv_files:\n",
    "    df = pd.read_csv(p, dtype=str, keep_default_na=False, na_values=[\"\", \"NULL\"])\n",
    "    df_std = pick_and_rename_columns(df)\n",
    "\n",
    "\n",
    "    for c in [\"ReceivedOuters\", \"ExpectedUnitPricePerOuter\"]:\n",
    "        df_std[c] = pd.to_numeric(df_std[c], errors=\"coerce\")\n",
    "\n",
    "    df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "\n",
    "    df_std = df_std.dropna(subset=[\"PurchaseOrderID\", \"PurchaseOrderLineID\", \"OrderDate\"])\n",
    "\n",
    "    df_std[\"ReceivedOuters\"] = df_std[\"ReceivedOuters\"].fillna(0)\n",
    "    df_std[\"ExpectedUnitPricePerOuter\"] = df_std[\"ExpectedUnitPricePerOuter\"].fillna(0)\n",
    "\n",
    "    frames.append(df_std)\n",
    "\n",
    "combined = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "combined.to_csv(OUT_CSV, index=False)\n",
    "print(f\"combine to 1：{OUT_CSV} line={len(combined):,}\")\n",
    "\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"ETHANAN2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"svogymj-bxb71103\") \n",
    ")\n",
    "cs = conn.cursor()\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB}.{SC}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH}\")\n",
    "cs.execute(f\"USE DATABASE {DB}\")\n",
    "cs.execute(f\"USE SCHEMA {SC}\")\n",
    "\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT csv_ff\n",
    "  TYPE = CSV\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY = '\\\"'\n",
    "  PARSE_HEADER = TRUE\n",
    "  NULL_IF = ('','NULL')\n",
    "  TRIM_SPACE = TRUE\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE purchases_detail (\n",
    "  PurchaseOrderID           STRING,\n",
    "  PurchaseOrderLineID       STRING,\n",
    "  ReceivedOuters            NUMBER(18,4),\n",
    "  ExpectedUnitPricePerOuter NUMBER(18,4),\n",
    "  OrderDate                 DATE,\n",
    "  SupplierID                STRING\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(f\"PUT 'file:///{OUT_CSV.as_posix()}' @purchases_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO'\")\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO purchases_detail\n",
    "FROM @purchases_stage\n",
    "FILE_FORMAT=(FORMAT_NAME='csv_ff')\n",
    "MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\")\n",
    "\n",
    "# 10) 校验\n",
    "cs.execute(\"SELECT COUNT(*) FROM purchases_detail\")\n",
    "print(\"Snowflake 行数:\", cs.fetchone()[0])\n",
    "cs.execute(\"SELECT * FROM purchases_detail ORDER BY OrderDate, PurchaseOrderID LIMIT 5\")\n",
    "for row in cs.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cs.close(); conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
