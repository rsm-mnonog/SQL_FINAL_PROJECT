{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.12/site-packages (3.17.3)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.40.25)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (45.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.1.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.2)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.32.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2025.6.15)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.14.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (3.19.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (4.3.8)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.12/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0->snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user= 'mnonog',\n",
    "    password = 'KayaNatinToL0RD!',\n",
    "    account='cejmwpt-djb91267'\n",
    "    )\n",
    "\n",
    "#https://cejmwpt-djb91267.snowflakecomputing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cs:\n",
    "    # warehouse + db/schema setup\n",
    "    cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS my_first_warehouse\")\n",
    "    cs.execute(\"CREATE DATABASE IF NOT EXISTS testdb\")\n",
    "    cs.execute(\"USE DATABASE testdb\")          # üëà set current DB\n",
    "    cs.execute(\"CREATE SCHEMA IF NOT EXISTS testschema\")\n",
    "    cs.execute( \"CREATE OR REPLACE TABLE \"    \n",
    "             \"test_table(col1 integer, col2 string)\")\n",
    "    cs.execute(\"INSERT INTO test_table(col1, col2) \"\n",
    "    \t\t\"VALUES (123, 'test string1'), (456, 'test string2')\")\n",
    "    \n",
    "    #  stages \n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS invoices_stage\")\n",
    "    cs.execute(\"CREATE STAGE IF NOT EXISTS supplier_stage\")\n",
    "    \n",
    "    # File formats\n",
    "    cs.execute(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT csv_ff \n",
    "        TYPE = CSV \n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "        SKIP_HEADER = 1 \n",
    "        NULL_IF = ('', 'NULL')\n",
    "    \"\"\")\n",
    "    \n",
    "    cs.execute(\"\"\"\n",
    "        CREATE OR REPLACE FILE FORMAT xml_ff \n",
    "        TYPE = XML \n",
    "        STRIP_OUTER_ELEMENT = TRUE\n",
    "    \"\"\")\n",
    "    # cs.execute('SELECT * FROM test_table')\n",
    "    # print(cs.fetchmany(2))\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (6.0.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary pandas lxml python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/868590347.py:75: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine to 1Ôºö/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5/Monthly PO Data/combined_purchases.csv line=229,124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowflake.connector as sf\n",
    "\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "BASE_DIR = Path(r\"/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5/Monthly PO Data\").resolve()\n",
    "OUT_CSV  = BASE_DIR / \"combined_purchases.csv\"   # Áªü‰∏ÄËæìÂá∫Êñá‰ª∂\n",
    "\n",
    "# 2) ÈúÄË¶Å‰øùÁïôÂπ∂Ê†áÂáÜÂåñÂà∞ Snowflake ÁöÑÂàóÔºàÁõÆÊ†áÂàóÂêçÔºâ\n",
    "TARGET_COLS = [\n",
    "    \"PurchaseOrderID\",\n",
    "    \"PurchaseOrderLineID\",\n",
    "    \"ReceivedOuters\",\n",
    "    \"ExpectedUnitPricePerOuter\",\n",
    "    \"OrderDate\",\n",
    "    \"SupplierID\",\n",
    "]\n",
    "\n",
    "# 3) ÂàóÂêçÂà´ÂêçË°®ÔºàÂ∞ΩÈáèË¶ÜÁõñ‰Ω†Êñá‰ª∂ÈáåÁöÑÂêÑÁßçÂÜôÊ≥ïÔºõ‰∏çÂ§üÁöÑËØùÂÜçÂä†Âá†ÁßçÔºâ\n",
    "ALIASES = {\n",
    "    \"PurchaseOrderID\":           [\"purchaseorderid\", \"purchase_order_id\", \"poid\", \"orderid\"],\n",
    "    \"PurchaseOrderLineID\":       [\"purchaseorderlineid\", \"purchase_order_line_id\", \"polineid\", \"orderlineid\"],\n",
    "    \"ReceivedOuters\":            [\"receivedouters\", \"received_outers\", \"receivedoutersqty\", \"receivedoutersquantity\", \"received_qty\"],\n",
    "    \"ExpectedUnitPricePerOuter\": [\"expectedunitpriceperouter\", \"expected_unit_price_per_outer\", \"unitpriceperouter\", \"expectedprice\", \"unitprice\"],\n",
    "    \"OrderDate\":                 [\"orderdate\", \"order_date\", \"date\", \"order_dt\"],\n",
    "    \"SupplierID\":                [\"supplierid\", \"supplier_id\", \"vendorid\", \"vendor_id\"],\n",
    "}\n",
    "\n",
    "def norm(name: str) -> str:\n",
    "    \"\"\"ËßÑËåÉÂåñÂàóÂêçÔºöÂè™‰øùÁïôÂ≠óÊØçÊï∞Â≠óÂπ∂Â∞èÂÜôÔºå‰æø‰∫éÂåπÈÖç\"\"\"\n",
    "    return \"\".join(ch.lower() for ch in name if ch.isalnum())\n",
    "\n",
    "def pick_and_rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"‰ªéÂéüÂßã df ÈáåÊåâÂà´ÂêçË°®ÊåëÂá∫ÈúÄË¶ÅÁöÑÂàóÔºåÂπ∂ÈáçÂëΩÂêç‰∏∫Ê†áÂáÜÂàóÂêç\"\"\"\n",
    "    orig_to_norm = {c: norm(c) for c in df.columns}\n",
    "    norm_to_orig = {v: k for k, v in orig_to_norm.items()}  # ÂèñÁ¨¨‰∏Ä‰∏™Âá∫Áé∞ÁöÑÊò†Â∞ÑÂç≥ÂèØ\n",
    "\n",
    "    selected = {}\n",
    "    missing  = []\n",
    "    for tgt, alias_list in ALIASES.items():\n",
    "        found = None\n",
    "        for alias in alias_list:\n",
    "            if alias in norm_to_orig:\n",
    "                found = norm_to_orig[alias]\n",
    "                break\n",
    "        if found is None:\n",
    "            missing.append(tgt)\n",
    "        else:\n",
    "            selected[tgt] = found\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"Áº∫Â∞ëÂøÖÈ°ªÂàóÔºö{missing}; Êñá‰ª∂Âàó={list(df.columns)}\")\n",
    "\n",
    "\n",
    "    out = df[[selected[c] for c in TARGET_COLS]].copy()\n",
    "    out.columns = TARGET_COLS\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "csv_files = sorted(BASE_DIR.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"Âú® {BASE_DIR} ‰∏ãÊ≤°ÊúâÊâæÂà∞ .csv Êñá‰ª∂\")\n",
    "\n",
    "for p in csv_files:\n",
    "    df = pd.read_csv(p, dtype=str, keep_default_na=False, na_values=[\"\", \"NULL\"])\n",
    "    df_std = pick_and_rename_columns(df)\n",
    "\n",
    "\n",
    "    for c in [\"ReceivedOuters\", \"ExpectedUnitPricePerOuter\"]:\n",
    "        df_std[c] = pd.to_numeric(df_std[c], errors=\"coerce\")\n",
    "\n",
    "    df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "\n",
    "    df_std = df_std.dropna(subset=[\"PurchaseOrderID\", \"PurchaseOrderLineID\", \"OrderDate\"])\n",
    "\n",
    "    df_std[\"ReceivedOuters\"] = df_std[\"ReceivedOuters\"].fillna(0)\n",
    "    df_std[\"ExpectedUnitPricePerOuter\"] = df_std[\"ExpectedUnitPricePerOuter\"].fillna(0)\n",
    "\n",
    "    frames.append(df_std)\n",
    "\n",
    "combined = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "combined.to_csv(OUT_CSV, index=False)\n",
    "print(f\"combine to 1Ôºö{OUT_CSV} line={len(combined):,}\")\n",
    "\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"ETHANAN2000\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"An67087833@123\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"svogymj-bxb71103\") \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffffabd5bb90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = conn.cursor()\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB}.{SC}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH}\")\n",
    "cs.execute(f\"USE DATABASE {DB}\")\n",
    "cs.execute(f\"USE SCHEMA {SC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffffabd5bb90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT csv_ff\n",
    "  TYPE = CSV\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY = '\\\"'\n",
    "  PARSE_HEADER = TRUE\n",
    "  NULL_IF = ('','NULL')\n",
    "  TRIM_SPACE = TRUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffffabd5bb90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE purchases_detail (\n",
    "  PurchaseOrderID           STRING,\n",
    "  PurchaseOrderLineID       STRING,\n",
    "  ReceivedOuters            NUMBER(18,4),\n",
    "  ExpectedUnitPricePerOuter NUMBER(18,4),\n",
    "  OrderDate                 DATE,\n",
    "  SupplierID                STRING\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Ë°åÊï∞: 229124\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '3', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cs.execute(f\"PUT 'file:///{OUT_CSV.as_posix()}' @purchases_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO'\")\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO purchases_detail\n",
    "FROM @purchases_stage\n",
    "FILE_FORMAT=(FORMAT_NAME='csv_ff')\n",
    "MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# 10) Ê†°È™å\n",
    "cs.execute(\"SELECT COUNT(*) FROM purchases_detail\")\n",
    "print(\"Snowflake Ë°åÊï∞:\", cs.fetchone()[0])\n",
    "cs.execute(\"SELECT * FROM purchases_detail ORDER BY OrderDate, PurchaseOrderID LIMIT 5\")\n",
    "for row in cs.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cs.close(); conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Warehouse and Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff6b4902c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import snowflake.connector as sf\n",
    "\n",
    "\n",
    "\n",
    "# === Âª∫ËÆÆÁî®ÁéØÂ¢ÉÂèòÈáè/ .env ===\n",
    "SNOW_USER=os.getenv(\"SNOW_USER\",\"<mnonog>\")\n",
    "SNOW_PASSWORD=os.getenv(\"SNOW_PASSWORD\",\"<KayaNatinToL0RD!>\")\n",
    "SNOW_ACCOUNT=os.getenv(\"SNOW_ACCOUNT\",\"cejmwpt-djb91267\")   # Âè™ÂÜôÊ†áËØÜÔºå‰∏çË¶ÅÂÜô https://...\n",
    "SNOW_ROLE=os.getenv(\"SNOW_ROLE\",\"ACCOUNTADMIN\")\n",
    "WH_NAME=os.getenv(\"SNOW_WH\",\"ETL_WH\")\n",
    "DB_NAME=os.getenv(\"SNOW_DB\",\"ETL_DB\")\n",
    "SCHEMA_NAME=os.getenv(\"SNOW_SCHEMA\",\"ETL_SCHEMA\")\n",
    "\n",
    "conn = sf.connect(user='mnonog', password='KayaNatinToL0RD!', account='cejmwpt-djb91267')\n",
    "cs = conn.cursor()\n",
    "\n",
    "# Âü∫Á°ÄÂØπË±°\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH_NAME} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB_NAME}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB_NAME}.{SCHEMA_NAME}\")\n",
    "cs.execute(f\"USE ROLE {SNOW_ROLE}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH_NAME}\")\n",
    "cs.execute(f\"USE DATABASE {DB_NAME}\")\n",
    "cs.execute(f\"USE SCHEMA {SCHEMA_NAME}\")\n",
    "\n",
    "# Áªü‰∏Ä stage / Êñá‰ª∂Ê†ºÂºè\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS invoices_stage\")\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS supplier_stage\")\n",
    "\n",
    "cs.execute(\"\"\"CREATE OR REPLACE FILE FORMAT csv_ff \n",
    "  TYPE=CSV FIELD_OPTIONALLY_ENCLOSED_BY='\\\"' SKIP_HEADER=1 NULL_IF=('','NULL')\"\"\")\n",
    "cs.execute(\"\"\"CREATE OR REPLACE FILE FORMAT xml_ff TYPE=XML STRIP_OUTER_ELEMENT=TRUE\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Snowflakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"mnonog\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"KayaNatinToL0RD!\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"cejmwpt-djb91267\")  # Âè™ÂÜôÊ†áËØÜÔºå‰∏çË¶Å https:// ÂâçÁºÄ\n",
    ")\n",
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Task 1 and 2: Creating Single Table of Purchases Data and Adding the POAmount Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
      "/tmp/ipykernel_93494/4052790598.py:73: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine to 1Ôºö/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5/Monthly PO Data/combined_purchases.csv line=237,307\n",
      "Snowflake Ë°åÊï∞: 237307\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '3', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '2', Decimal('21.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n",
      "('1', '1', Decimal('18.0000'), Decimal('5.5000'), datetime.date(2019, 1, 1), '2')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffffa938af30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowflake.connector as sf\n",
    "\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "BASE_DIR = Path(r\"/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5/Monthly PO Data\").resolve()\n",
    "OUT_CSV  = BASE_DIR / \"combined_purchases.csv\"   # Áªü‰∏ÄËæìÂá∫Êñá‰ª∂\n",
    "\n",
    "# 2) ÈúÄË¶Å‰øùÁïôÂπ∂Ê†áÂáÜÂåñÂà∞ Snowflake ÁöÑÂàóÔºàÁõÆÊ†áÂàóÂêçÔºâ\n",
    "TARGET_COLS = [\n",
    "    \"PurchaseOrderID\",\n",
    "    \"PurchaseOrderLineID\",\n",
    "    \"ReceivedOuters\",\n",
    "    \"ExpectedUnitPricePerOuter\",\n",
    "    \"OrderDate\",\n",
    "    \"SupplierID\",\n",
    "]\n",
    "\n",
    "# 3) ÂàóÂêçÂà´ÂêçË°®ÔºàÂ∞ΩÈáèË¶ÜÁõñ‰Ω†Êñá‰ª∂ÈáåÁöÑÂêÑÁßçÂÜôÊ≥ïÔºõ‰∏çÂ§üÁöÑËØùÂÜçÂä†Âá†ÁßçÔºâ\n",
    "ALIASES = {\n",
    "    \"PurchaseOrderID\":           [\"purchaseorderid\", \"purchase_order_id\", \"poid\", \"orderid\"],\n",
    "    \"PurchaseOrderLineID\":       [\"purchaseorderlineid\", \"purchase_order_line_id\", \"polineid\", \"orderlineid\"],\n",
    "    \"ReceivedOuters\":            [\"receivedouters\", \"received_outers\", \"receivedoutersqty\", \"receivedoutersquantity\", \"received_qty\"],\n",
    "    \"ExpectedUnitPricePerOuter\": [\"expectedunitpriceperouter\", \"expected_unit_price_per_outer\", \"unitpriceperouter\", \"expectedprice\", \"unitprice\"],\n",
    "    \"OrderDate\":                 [\"orderdate\", \"order_date\", \"date\", \"order_dt\"],\n",
    "    \"SupplierID\":                [\"supplierid\", \"supplier_id\", \"vendorid\", \"vendor_id\"],\n",
    "}\n",
    "\n",
    "def norm(name: str) -> str:\n",
    "    return \"\".join(ch.lower() for ch in name if ch.isalnum())\n",
    "\n",
    "def pick_and_rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    orig_to_norm = {c: norm(c) for c in df.columns}\n",
    "    norm_to_orig = {v: k for k, v in orig_to_norm.items()}  # ÂèñÁ¨¨‰∏Ä‰∏™Âá∫Áé∞ÁöÑÊò†Â∞ÑÂç≥ÂèØ\n",
    "\n",
    "    selected = {}\n",
    "    missing  = []\n",
    "    for tgt, alias_list in ALIASES.items():\n",
    "        found = None\n",
    "        for alias in alias_list:\n",
    "            if alias in norm_to_orig:\n",
    "                found = norm_to_orig[alias]\n",
    "                break\n",
    "        if found is None:\n",
    "            missing.append(tgt)\n",
    "        else:\n",
    "            selected[tgt] = found\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"Áº∫Â∞ëÂøÖÈ°ªÂàóÔºö{missing}; Êñá‰ª∂Âàó={list(df.columns)}\")\n",
    "\n",
    "\n",
    "    out = df[[selected[c] for c in TARGET_COLS]].copy()\n",
    "    out.columns = TARGET_COLS\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "csv_files = sorted(BASE_DIR.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"Âú® {BASE_DIR} ‰∏ãÊ≤°ÊúâÊâæÂà∞ .csv Êñá‰ª∂\")\n",
    "\n",
    "for p in csv_files:\n",
    "    df = pd.read_csv(p, dtype=str, keep_default_na=False, na_values=[\"\", \"NULL\"])\n",
    "    df_std = pick_and_rename_columns(df)\n",
    "\n",
    "\n",
    "    for c in [\"ReceivedOuters\", \"ExpectedUnitPricePerOuter\"]:\n",
    "        df_std[c] = pd.to_numeric(df_std[c], errors=\"coerce\")\n",
    "\n",
    "    df_std[\"OrderDate\"] = pd.to_datetime(df_std[\"OrderDate\"], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "\n",
    "    df_std = df_std.dropna(subset=[\"PurchaseOrderID\", \"PurchaseOrderLineID\", \"OrderDate\"])\n",
    "\n",
    "    df_std[\"ReceivedOuters\"] = df_std[\"ReceivedOuters\"].fillna(0)\n",
    "    df_std[\"ExpectedUnitPricePerOuter\"] = df_std[\"ExpectedUnitPricePerOuter\"].fillna(0)\n",
    "\n",
    "    frames.append(df_std)\n",
    "\n",
    "combined = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "combined.to_csv(OUT_CSV, index=False)\n",
    "print(f\"combine to 1Ôºö{OUT_CSV} line={len(combined):,}\")\n",
    "\n",
    "conn = sf.connect(\n",
    "    user=os.getenv(\"SNOW_USER\", \"mnonog\"),\n",
    "    password=os.getenv(\"SNOW_PASSWORD\", \"KayaNatinToL0RD!\"),\n",
    "    account=os.getenv(\"SNOW_ACCOUNT\", \"cejmwpt-djb91267\") \n",
    ")\n",
    "\n",
    "cs = conn.cursor()\n",
    "\n",
    "WH, DB, SC = \"ETL_WH\", \"ETL_DB\", \"ETL_SCHEMA\"\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {WH} WAREHOUSE_SIZE=SMALL AUTO_SUSPEND=60 AUTO_RESUME=TRUE\")\n",
    "cs.execute(f\"CREATE DATABASE  IF NOT EXISTS {DB}\")\n",
    "cs.execute(f\"CREATE SCHEMA    IF NOT EXISTS {DB}.{SC}\")\n",
    "cs.execute(f\"USE WAREHOUSE {WH}\")\n",
    "cs.execute(f\"USE DATABASE {DB}\")\n",
    "cs.execute(f\"USE SCHEMA {SC}\")\n",
    "\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS purchases_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT csv_ff\n",
    "  TYPE = CSV\n",
    "  FIELD_OPTIONALLY_ENCLOSED_BY = '\\\"'\n",
    "  PARSE_HEADER = TRUE\n",
    "  NULL_IF = ('','NULL')\n",
    "  TRIM_SPACE = TRUE\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE purchases_detail (\n",
    "  PurchaseOrderID           STRING,\n",
    "  PurchaseOrderLineID       STRING,\n",
    "  ReceivedOuters            NUMBER(18,4),\n",
    "  ExpectedUnitPricePerOuter NUMBER(18,4),\n",
    "  OrderDate                 DATE,\n",
    "  SupplierID                STRING\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "cs.execute(f\"PUT 'file:///{OUT_CSV.as_posix()}' @purchases_stage AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO'\")\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO purchases_detail\n",
    "FROM @purchases_stage\n",
    "FILE_FORMAT=(FORMAT_NAME='csv_ff')\n",
    "MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\")\n",
    "\n",
    "# 10) Ê†°È™å\n",
    "cs.execute(\"SELECT COUNT(*) FROM purchases_detail\")\n",
    "print(\"Snowflake Ë°åÊï∞:\", cs.fetchone()[0])\n",
    "cs.execute(\"SELECT * FROM purchases_detail ORDER BY OrderDate, PurchaseOrderID LIMIT 5\")\n",
    "for row in cs.fetchall():\n",
    "    print(row)\n",
    "  \n",
    "    \n",
    "# line-level view\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW PurchaseOrderTotals AS\n",
    "SELECT\n",
    "  PurchaseOrderID,\n",
    "  PurchaseOrderLineID,\n",
    "  ReceivedOuters,\n",
    "  ExpectedUnitPricePerOuter,\n",
    "  OrderDate,\n",
    "  SupplierID,\n",
    "  SUM(ReceivedOuters * ExpectedUnitPricePerOuter)\n",
    "    OVER (PARTITION BY PurchaseOrderID) AS POAmount\n",
    "FROM purchases_detail\n",
    "ORDER BY PurchaseOrderID, PurchaseOrderLineID\n",
    "\"\"\")\n",
    "\n",
    "# add column (no-op if it already exists; remove OR REPLACE since Snowflake doesn't support it on columns)\n",
    "cs.execute(\"ALTER TABLE purchases_detail ADD COLUMN POAmount NUMBER(18,2)\")\n",
    "\n",
    "# backfill totals (same POAmount for all lines of the same order)\n",
    "cs.execute(\"\"\"\n",
    "UPDATE purchases_detail AS pd\n",
    "SET POAmount = t.POAmount\n",
    "FROM (\n",
    "  SELECT\n",
    "    PurchaseOrderID,\n",
    "    ROUND(SUM(ReceivedOuters * ExpectedUnitPricePerOuter), 2) AS POAmount\n",
    "  FROM purchases_detail\n",
    "  GROUP BY PurchaseOrderID\n",
    ") AS t\n",
    "WHERE pd.PurchaseOrderID = t.PurchaseOrderID\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoices_stage/incoming/Supplier Transactions XML.xml.gz', 72528, 'c1f7dea87b23878052a0201ed1c68223', 'Thu, 11 Sep 2025 05:09:34 GMT')]\n",
      "supplier_invoices rows: 2438\n",
      "(134, 2, 5, 1, 4, '7290', datetime.date(2019, 1, 2), Decimal('313.50'), Decimal('47.03'), Decimal('360.53'), Decimal('0.00'), datetime.date(2019, 1, 7), True, 4, 'incoming/Supplier Transactions XML.xml.gz')\n",
      "(169, 4, 5, 2, 4, '3898', datetime.date(2019, 1, 2), Decimal('21732.00'), Decimal('3259.80'), Decimal('24991.80'), Decimal('0.00'), datetime.date(2019, 1, 7), True, 4, 'incoming/Supplier Transactions XML.xml.gz')\n",
      "(186, 5, 5, 3, 4, '616', datetime.date(2019, 1, 2), Decimal('2740.50'), Decimal('411.11'), Decimal('3151.61'), Decimal('0.00'), datetime.date(2019, 1, 7), True, 4, 'incoming/Supplier Transactions XML.xml.gz')\n",
      "(215, 7, 5, 4, 4, '3869', datetime.date(2019, 1, 2), Decimal('42481.20'), Decimal('6372.19'), Decimal('48853.39'), Decimal('0.00'), datetime.date(2019, 1, 7), True, 4, 'incoming/Supplier Transactions XML.xml.gz')\n",
      "(224, 10, 5, 5, 4, '4697', datetime.date(2019, 1, 2), Decimal('35067.50'), Decimal('5260.14'), Decimal('40327.64'), Decimal('0.00'), datetime.date(2019, 1, 7), True, 4, 'incoming/Supplier Transactions XML.xml.gz')\n"
     ]
    }
   ],
   "source": [
    "# === 3) Extract & load supplier invoice XML (one row per invoice) ===\n",
    "\n",
    "# File format + stage (idempotent)\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS invoices_stage\")\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT xml_ff\n",
    "  TYPE = XML\n",
    "  STRIP_OUTER_ELEMENT = TRUE\n",
    "\"\"\")\n",
    "\n",
    "# Your XML file path\n",
    "XML_FILE = Path(\"/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5/Supplier Transactions XML.xml\").resolve()\n",
    "\n",
    "# Keep XML isolated in a subfolder\n",
    "cs.execute(f\"PUT 'file:///{XML_FILE.as_posix()}' @invoices_stage/incoming AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "\n",
    "# (optional) sanity check\n",
    "cs.execute(\"LIST @invoices_stage/incoming\"); print(cs.fetchall())\n",
    "\n",
    "# 1) Land raw XML into a VARIANT table (simple COPY is required)\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_invoices_raw (\n",
    "  doc VARIANT,\n",
    "  sourcefile STRING\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO supplier_invoices_raw (doc, sourcefile)\n",
    "FROM (\n",
    "  SELECT $1, METADATA$FILENAME\n",
    "  FROM @invoices_stage/incoming (FILE_FORMAT => 'xml_ff')\n",
    ")\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\")\n",
    "\n",
    "# 2) Final relational table (one row = one invoice)\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_invoices (\n",
    "  SupplierTransactionID NUMBER,\n",
    "  SupplierID            NUMBER,\n",
    "  TransactionTypeID     NUMBER,\n",
    "  PurchaseOrderID       NUMBER,\n",
    "  PaymentMethodID       NUMBER,\n",
    "  SupplierInvoiceNumber STRING,\n",
    "  TransactionDate       DATE,\n",
    "  AmountExcludingTax    NUMBER(18,2),\n",
    "  TaxAmount             NUMBER(18,2),\n",
    "  TransactionAmount     NUMBER(18,2),\n",
    "  OutstandingBalance    NUMBER(18,2),\n",
    "  FinalizationDate      DATE,\n",
    "  IsFinalized           BOOLEAN,\n",
    "  LastEditedBy          NUMBER,\n",
    "  SourceFile            STRING\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO', TIMESTAMP_INPUT_FORMAT='AUTO'\")\n",
    "\n",
    "# 3) Shred XML from RAW -> FINAL using the hinted functions\n",
    "#    (handles either <root><row>...</row></root> OR already-row-level documents)\n",
    "cs.execute(\"\"\"\n",
    "INSERT INTO supplier_invoices\n",
    "SELECT\n",
    "  TRY_TO_NUMBER(GET(XMLGET(f.value,'SupplierTransactionID'), '$')::string)              AS SupplierTransactionID,\n",
    "  TRY_TO_NUMBER(GET(XMLGET(f.value,'SupplierID'), '$')::string)                         AS SupplierID,\n",
    "  TRY_TO_NUMBER(GET(XMLGET(f.value,'TransactionTypeID'), '$')::string)                  AS TransactionTypeID,\n",
    "  TRY_TO_NUMBER(GET(XMLGET(f.value,'PurchaseOrderID'), '$')::string)                    AS PurchaseOrderID,\n",
    "  TRY_TO_NUMBER(GET(XMLGET(f.value,'PaymentMethodID'), '$')::string)                    AS PaymentMethodID,\n",
    "  XMLGET(f.value,'SupplierInvoiceNumber'):\"$\"::string                                    AS SupplierInvoiceNumber,\n",
    "  TRY_TO_DATE(XMLGET(f.value,'TransactionDate'):\"$\"::string)                            AS TransactionDate,\n",
    "  TRY_TO_NUMBER(REPLACE(XMLGET(f.value,'AmountExcludingTax'):\"$\"::string, ',', ''),38,2) AS AmountExcludingTax,\n",
    "  TRY_TO_NUMBER(REPLACE(XMLGET(f.value,'TaxAmount'):\"$\"::string, ',', ''),38,2)          AS TaxAmount,\n",
    "  TRY_TO_NUMBER(REPLACE(XMLGET(f.value,'TransactionAmount'):\"$\"::string, ',', ''),38,2)  AS TransactionAmount,\n",
    "  TRY_TO_NUMBER(REPLACE(XMLGET(f.value,'OutstandingBalance'):\"$\"::string, ',', ''),38,2) AS OutstandingBalance,\n",
    "  TRY_TO_DATE(XMLGET(f.value,'FinalizationDate'):\"$\"::string)                           AS FinalizationDate,\n",
    "  IFF(LOWER(NULLIF(XMLGET(f.value,'IsFinalized'):\"$\"::string,'')) IN ('1','true','yes'),\n",
    "      TRUE, FALSE)                                                                       AS IsFinalized,\n",
    "  TRY_TO_NUMBER(XMLGET(f.value,'LastEditedBy'):\"$\"::string)                             AS LastEditedBy,\n",
    "  r.sourcefile                                                                           AS SourceFile\n",
    "FROM supplier_invoices_raw r,\n",
    "     LATERAL FLATTEN(\n",
    "       input => IFF(IS_ARRAY(r.doc:root.row), r.doc:root.row, ARRAY_CONSTRUCT(r.doc))\n",
    "     ) f\n",
    "\"\"\")\n",
    "\n",
    "# verify\n",
    "cs.execute(\"SELECT COUNT(*) FROM supplier_invoices\")\n",
    "print(\"supplier_invoices rows:\", cs.fetchone()[0])\n",
    "cs.execute(\"SELECT * FROM supplier_invoices ORDER BY TransactionDate, SupplierTransactionID LIMIT 5\")\n",
    "for r in cs.fetchall():\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffffa938af30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(f\"\"\"\n",
    "CREATE OR REPLACE VIEW {DB}.{SC}.po_invoice_join_vw AS\n",
    "SELECT\n",
    "  d.PurchaseOrderID,\n",
    "  d.PurchaseOrderLineID,\n",
    "  d.SupplierID,\n",
    "  d.OrderDate,\n",
    "  d.ReceivedOuters,\n",
    "  d.ExpectedUnitPricePerOuter,\n",
    "  i.SupplierTransactionID,\n",
    "  i.SupplierInvoiceNumber,\n",
    "  i.TransactionDate   AS InvoiceDate,\n",
    "  i.TransactionAmount AS InvoiceAmount\n",
    "FROM {DB}.{SC}.purchases_detail d\n",
    "JOIN {DB}.{SC}.supplier_invoices i\n",
    "  ON TRY_TO_NUMBER(d.PurchaseOrderID) = i.PurchaseOrderID\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materialized view not supported for this definition; creating TABLE instead. Reason: 001998 (42710): SQL compilation error:\n",
      "Object 'PURCHASE_ORDERS_AND_INVOICES' already exists as TABLE\n",
      "Created TABLE: ETL_DB.ETL_SCHEMA.purchase_orders_and_invoices\n",
      "Rows in purchase_orders_and_invoices: 2023\n",
      "(1, 2, Decimal('9091.50'), Decimal('313.50'), Decimal('-8778.00'))\n",
      "(2, 4, Decimal('630228.00'), Decimal('21732.00'), Decimal('-608496.00'))\n",
      "(3, 5, Decimal('79474.50'), Decimal('2740.50'), Decimal('-76734.00'))\n",
      "(4, 7, Decimal('1231954.80'), Decimal('42481.20'), Decimal('-1189473.60'))\n",
      "(5, 10, Decimal('1016957.50'), Decimal('35067.50'), Decimal('-981890.00'))\n",
      "(6, 12, Decimal('160326.50'), Decimal('5528.50'), Decimal('-154798.00'))\n",
      "(7, 4, Decimal('290014.50'), Decimal('10000.50'), Decimal('-280014.00'))\n",
      "(8, 5, Decimal('19053.00'), Decimal('657.00'), Decimal('-18396.00'))\n",
      "(9, 7, Decimal('269163.50'), Decimal('9281.50'), Decimal('-259882.00'))\n",
      "(10, 10, Decimal('30087.50'), Decimal('1037.50'), Decimal('-29050.00'))\n"
     ]
    }
   ],
   "source": [
    "# === 5) purchase_orders_and_invoices (MV if possible, else TABLE) ===\n",
    "\n",
    "# 5.1 Build a PO header total at the order level (typed as NUMBER to match invoices)\n",
    "cs.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {DB}.{SC}.po_header_totals_tmp AS\n",
    "SELECT\n",
    "  TRY_TO_NUMBER(PurchaseOrderID) AS PurchaseOrderID,\n",
    "  TRY_TO_NUMBER(SupplierID)      AS SupplierID,\n",
    "  MIN(OrderDate)                 AS OrderDate,\n",
    "  ROUND(SUM(ReceivedOuters * ExpectedUnitPricePerOuter), 2) AS POAmount\n",
    "FROM {DB}.{SC}.purchases_detail\n",
    "GROUP BY 1,2\n",
    "\"\"\")\n",
    "\n",
    "# 5.2 Attempt Materialized View (fallback to TABLE if MV not supported for this join)\n",
    "create_mv_sql = f\"\"\"\n",
    "CREATE OR REPLACE MATERIALIZED VIEW {DB}.{SC}.purchase_orders_and_invoices AS\n",
    "SELECT\n",
    "  p.PurchaseOrderID,\n",
    "  p.SupplierID,\n",
    "  p.OrderDate,\n",
    "  p.POAmount,\n",
    "  i.SupplierTransactionID,\n",
    "  i.SupplierInvoiceNumber,\n",
    "  i.TransactionDate      AS InvoiceDate,\n",
    "  i.AmountExcludingTax,\n",
    "  i.TransactionAmount,\n",
    "  ROUND(i.AmountExcludingTax - p.POAmount, 2) AS invoiced_vs_quoted\n",
    "FROM {DB}.{SC}.po_header_totals_tmp p\n",
    "JOIN {DB}.{SC}.supplier_invoices i\n",
    "  ON p.PurchaseOrderID = i.PurchaseOrderID\n",
    " AND p.SupplierID      = i.SupplierID\n",
    "\"\"\"\n",
    "\n",
    "create_tbl_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {DB}.{SC}.purchase_orders_and_invoices AS\n",
    "SELECT\n",
    "  p.PurchaseOrderID,\n",
    "  p.SupplierID,\n",
    "  p.OrderDate,\n",
    "  p.POAmount,\n",
    "  i.SupplierTransactionID,\n",
    "  i.SupplierInvoiceNumber,\n",
    "  i.TransactionDate      AS InvoiceDate,\n",
    "  i.AmountExcludingTax,\n",
    "  i.TransactionAmount,\n",
    "  ROUND(i.AmountExcludingTax - p.POAmount, 2) AS invoiced_vs_quoted\n",
    "FROM {DB}.{SC}.po_header_totals_tmp p\n",
    "JOIN {DB}.{SC}.supplier_invoices i\n",
    "  ON p.PurchaseOrderID = i.PurchaseOrderID\n",
    " AND p.SupplierID      = i.SupplierID\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cs.execute(create_mv_sql)\n",
    "    print(\"Created MATERIALIZED VIEW:\", f\"{DB}.{SC}.purchase_orders_and_invoices\")\n",
    "except Exception as e:\n",
    "    print(\"Materialized view not supported for this definition; creating TABLE instead. Reason:\", str(e)[:140])\n",
    "    cs.execute(create_tbl_sql)\n",
    "    print(\"Created TABLE:\", f\"{DB}.{SC}.purchase_orders_and_invoices\")\n",
    "\n",
    "# 5.3 Quick sanity checks\n",
    "cs.execute(f\"SELECT COUNT(*) FROM {DB}.{SC}.purchase_orders_and_invoices\")\n",
    "print(\"Rows in purchase_orders_and_invoices:\", cs.fetchone()[0])\n",
    "\n",
    "cs.execute(f\"\"\"\n",
    "SELECT PurchaseOrderID, SupplierID, POAmount, AmountExcludingTax, invoiced_vs_quoted\n",
    "FROM {DB}.{SC}.purchase_orders_and_invoices\n",
    "ORDER BY PurchaseOrderID\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "for r in cs.fetchall():\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6) Extract supplier_case from Postgres ‚Üí local CSV ‚Üí Snowflake stage ===\n",
    "# Requires: pip install psycopg2-binary\n",
    "\n",
    "import psycopg2, re\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Postgres connection (env or defaults) ----\n",
    "PGHOST = os.getenv(\"PGHOST\", \"localhost\")\n",
    "PGPORT = int(os.getenv(\"PGPORT\", \"5432\"))\n",
    "PGUSER = os.getenv(\"PGUSER\", \"postgres\")\n",
    "PGPASSWORD = os.getenv(\"PGPASSWORD\", \"postgres\")\n",
    "PGDATABASE = os.getenv(\"PGDATABASE\", \"postgres\")\n",
    "\n",
    "EXPORT_DIR = Path(\"/home/jovyan/Desktop/SQL/SQL_FINAL_PROJECT/Data-5\").resolve()\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PG_CSV = EXPORT_DIR / \"supplier_case.csv\"\n",
    "\n",
    "# 6a) Postgres ‚Üí CSV (server-side COPY to client, no pandas DataFrame)\n",
    "with psycopg2.connect(\n",
    "    host=PGHOST, port=PGPORT, user=PGUSER, password=PGPASSWORD, dbname=PGDATABASE\n",
    ") as pg_conn, pg_conn.cursor() as cur, open(PG_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    # If your table is in a schema, qualify it: schema_name.supplier_case\n",
    "    cur.copy_expert(\"COPY supplier_case TO STDOUT WITH CSV HEADER\", f)\n",
    "\n",
    "print(f\"Exported Postgres supplier_case -> {PG_CSV}\")\n",
    "\n",
    "# 6b) Push CSV into Snowflake stage (keep it tidy in a subfolder)\n",
    "cs.execute(f\"CREATE STAGE IF NOT EXISTS {DB}.{SC}.supplier_stage\")\n",
    "cs.execute(f\"PUT 'file:///{PG_CSV.as_posix()}' @{DB}.{SC}.supplier_stage/pg_export AUTO_COMPRESS=TRUE OVERWRITE=TRUE\")\n",
    "cs.execute(f\"LIST @{DB}.{SC}.supplier_stage/pg_export\")\n",
    "print(cs.fetchall())\n",
    "\n",
    "# ---- Helper: infer Snowflake column types from CSV sample ----\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "_int_re   = re.compile(r\"^[+-]?\\d+$\")\n",
    "_float_re = re.compile(r\"^[+-]?\\d*\\.\\d+$\")\n",
    "_bool_set = {\"true\",\"false\",\"t\",\"f\",\"1\",\"0\",\"yes\",\"no\"}\n",
    "\n",
    "def _looks_bool(v:str)->bool:\n",
    "    return v.lower() in _bool_set\n",
    "\n",
    "def _looks_int(v:str)->bool:\n",
    "    return _int_re.match(v) is not None\n",
    "\n",
    "def _looks_float(v:str)->bool:\n",
    "    return _float_re.match(v) is not None\n",
    "\n",
    "def _looks_date(v:str)->bool:\n",
    "    # let Snowflake parse flexibly; we only do a quick sniff\n",
    "    for fmt in (\"%Y-%m-%d\",\"%m/%d/%Y\",\"%Y/%m/%d\"):\n",
    "        try:\n",
    "            datetime.strptime(v, fmt); return True\n",
    "        except: pass\n",
    "    return False\n",
    "\n",
    "def _looks_ts(v:str)->bool:\n",
    "    for fmt in (\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%dT%H:%M:%S\",\"%m/%d/%Y %H:%M:%S\"):\n",
    "        try:\n",
    "            datetime.strptime(v, fmt); return True\n",
    "        except: pass\n",
    "    return False\n",
    "\n",
    "def generate_snowflake_ddl(csv_path: Path, fq_table: str, sample_rows:int=2000)->str:\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        cols = reader.fieldnames\n",
    "        # flags per column\n",
    "        flags = {c: {\"bool\":True,\"int\":True,\"float\":True,\"date\":True,\"ts\":True,\"scale\":0} for c in cols}\n",
    "        n=0\n",
    "        for row in reader:\n",
    "            n += 1\n",
    "            for c in cols:\n",
    "                v = (row[c] or \"\").strip()\n",
    "                if v==\"\":\n",
    "                    continue\n",
    "                if not _looks_bool(v):  flags[c][\"bool\"]=False\n",
    "                if _looks_int(v):\n",
    "                    pass\n",
    "                else:\n",
    "                    flags[c][\"int\"]=False\n",
    "                if _looks_float(v):\n",
    "                    # track decimal scale\n",
    "                    try:\n",
    "                        sc = len(v.split(\".\")[1])\n",
    "                        flags[c][\"scale\"] = max(flags[c][\"scale\"], sc)\n",
    "                    except: pass\n",
    "                else:\n",
    "                    flags[c][\"float\"]=False\n",
    "                if not _looks_date(v): flags[c][\"date\"]=False\n",
    "                if not _looks_ts(v):   flags[c][\"ts\"]=False\n",
    "            if n>=sample_rows: break\n",
    "\n",
    "    def pick_type(fl):\n",
    "        if fl[\"ts\"]:   return \"TIMESTAMP_NTZ\"\n",
    "        if fl[\"date\"]: return \"DATE\"\n",
    "        if fl[\"bool\"]: return \"BOOLEAN\"\n",
    "        if fl[\"int\"]:  return \"NUMBER(38,0)\"\n",
    "        if fl[\"float\"]:\n",
    "            sc = min(max(fl[\"scale\"], 2), 9)\n",
    "            return f\"NUMBER(38,{sc})\"\n",
    "        return \"STRING\"\n",
    "\n",
    "    # quote identifiers safely (handle spaces/mixed case)\n",
    "    def qident(name:str)->str:\n",
    "        return '\"' + name.replace('\"','\"\"') + '\"'\n",
    "\n",
    "    cols_sql = \",\\n  \".join(f\"{qident(c)} {pick_type(flags[c])}\" for c in cols)\n",
    "    return f\"CREATE OR REPLACE TABLE {fq_table} (\\n  {cols_sql}\\n)\"\n",
    "\n",
    "# 6c) Generate CREATE TABLE from CSV header + sample values\n",
    "fq_tbl = f\"{DB}.{SC}.supplier_case\"\n",
    "ddl = generate_snowflake_ddl(PG_CSV, fq_tbl, sample_rows=5000)\n",
    "print(\"DDL:\\n\", ddl)\n",
    "cs.execute(ddl)\n",
    "\n",
    "# 6d) COPY into the Snowflake table\n",
    "cs.execute(\"ALTER SESSION SET DATE_INPUT_FORMAT='AUTO', TIME_INPUT_FORMAT='AUTO', TIMESTAMP_INPUT_FORMAT='AUTO'\")\n",
    "cs.execute(f\"\"\"\n",
    "COPY INTO {fq_tbl}\n",
    "FROM @{DB}.{SC}.supplier_stage/pg_export\n",
    "FILE_FORMAT=(FORMAT_NAME='{DB}.{SC}.csv_ff')\n",
    "MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "PATTERN='.*supplier_case\\\\.csv\\\\.gz'\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "\"\"\")\n",
    "\n",
    "# quick check\n",
    "cs.execute(f\"SELECT COUNT(*) FROM {fq_tbl}\")\n",
    "print(\"supplier_case rows:\", cs.fetchone()[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
